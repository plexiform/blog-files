---
title: "Ethics, Gender, Measurement"
date: "2020-06-26"
tags: ["development_policy", "rct_design", "justice"]
---

**Ethics:**

Why do we regulate experiments on human subjects?

Nazi research outed during the Nuremberg trials and the Tuskegee syphilis trials. The latter was performed by US health services over the course of 1932 to 1972. They chosee to observe, and not treat black American sharecroppers from Alabama. 28 died of syphilis, 100 died for related reasons, 40 wives infected, 19 children born with congenital syphilis. People were lured to get tested under the guise of these tests being treatment. This horrendous experiment was outed in 1972 and resulted in a $10m win against the PHS. Next to nothing was learned.

What did we learn?

The victims lacked information and taken advantage of. They were lied to by a false incentive. They lacked a supportive infrastructure in an oppressive environment. They were ignorant and marginalized, poor and misled. Then there were the negative externalities, or shitty side effects, to their families.

How do we determine whether or not an experiment is worthwhile? What risks and damage are we willing to take?

The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research put out the Belmont report, which details ethical principles and guidelines. These guidelines apply to human subjects irrespective of where or for what purpose data was collected. Human subject means someone whose information was collected through some intervention or interaction. Research implies the results translate into generalizable knowledge. [consult slide]

Distinctions drawn between human subjects and firms, private and public data.

What are these principles?

1) Respect for persons - autonomy, consent, privacy protection, safeguards from exploitation or coersion

2) Beneficence - maximize benefits, minimize risks. This is open to interpretation and not as mechanical as the previous principle. How do you evaluate risks to subjects or those affected by the research (externalities and spillover)? How do you maximize people's well-being when you know they're unwell?

3) Justice - Is the study equitable? If not, why? 
[consult book]

Online training available.

Randomization in regards to these principles: it's considered unethical to harm people. In randomization, typically the primary concern is whether there is any harm caused to the treatment group or negative spillover effects.

Randomization bias can occur if the method of inducing or incentivizing people to randomize or consent introduces bias. One amelioration is typically to make the inducement small enough that it doesn't make that much of a difference (avoiding undue inducement). In poor countries, not much inducement is typically needed.



**Measurement:**

We consult our theory of change to determine what we measure.

We want to capture the factors that influence intermediate then final outcomes, as well as the general behaviors we're attempting to target. We can also control our measurements by including covariates in our regressions to increase precision (power, precision lecture). Additionally we can measure takeup, calculate ATT or CACE, and collect indicators that influence takeup. This also improves precision.

We'd also want to account for differences in subgroups affected by the program (heterogeneous treatment effects).

We want to see how generalizable the program is, and if the local conditions are similar.

*Woman as Policymakers (India):*

After India amended its federal government in 1992, power over local development programs transferred from states to Gram Panchayats, or village councils. These councils were made to reserve a third of their seating for women. Assignment of seats and positions was scheduled randomly by the government.

These Panchayats make decisions in 29 development-related areas, such as maternity care, child care, infrastructure, education, etc. Council members, or councilors, are elected every 5 years, and from among themselves elect a chairperson. The aim of this system brought about by the 73rd amendment was to decentralize these decisions.

Because Panchayats can cover large swaths of the population, it's mandated that they hold a general assembly every half a year to a year. They announce what they'd worked on and propose how they wish to spend their budget moving forward. They also regularly have office hours during which people can put forth requests and complaints.

So we measure the effects of the randomly assigned seats reserved for women in these Panchayats.

What are the assumptions and categories in this theory of change, and how can we measure them? Will reserved seats be filled? Will the democratic process play out as intended in order to observe the desired effect? What *is* the desired effect? If women are policymakers, will they effect changes geared more towards women, and how likely is that to happen?

Kelsey Jack assumes that we will get public goods in line with women's preferences as a result of the "woman as policymakers" program. This presupposes that those preferences are both voiced and represented, and has to take into account whether or not there is something preventing the women from effecting these changes.

We want to measure components of this theory of change, such as measuring women's versus men's preferences, how investments are allocated and if they reflect typical investments, say at home. We can also look at the public budget just to see how that's been working out.


We want send out enumerators to understand issue priorities between men and women, and going off of the areas where these priorities differ (e.g. women valuing drinking water more than men), compare differences in those areas in quota versus non-quota villages.

**Results:**

*West Bengal:*

~9 more drinking water facilities than their non-quota counterparts (reflects issue priority differences)

On a scale of 0-1, 0.18 difference in road condition. (reflects)

Differences in irrigation not statistically significant. (doesn't reflect)

Education is valued more than men, no statistically different results

*Rajasthan:*

~2.6 more drinking facilities (reflects priority differences)

On a scale of 0-1, -0.08 difference in road condition. (reflects)

Differences in irrigation not statistically significant. (doesn't reflect)

Education is valued more than men, no stat. sig. diff.


Priors may be wrong. Worth measuring. Education result is surprising.

**How to Measure:**

You can always get public data. This may, at times, be found lacking. People who work in administrative or city planning roles might consider using this data for their logframes.

How do we collect primary data (what researchers (or those who "wear the evaluator's hat") collect)? This data is being collected for the first time.

You can get this from a person or be automatically generated. It can be about people or about other things, such as environmental or city measurements.

Surveys, exams, games, vignettes (recall the media experiments by Don Green, or in the "Woman as Policymakers" study by assessing people's reactions to different sexes as actors), diaries, direct observations, interviews, etc.

How do we determine the quality of these sources? How do we design them?

True baseline needs to be before the intervention. Heterogeneous treatment effects needs be accounted for. Subgroup analysis can help avoid missing key insights.

Endline captures the moments the intervention ends, whereas follow-up can trace ripples or effects in a longer horizon.

**Measurement Concepts:**

Construct (what we want to affect) -> Indicators -> Data collection ("response") -> Data

How valid something is is how well the indicator maps to the underlying construct.

Height is precise. BMI is precise but inaccurate (as far as health is concerned).

Reliability of the indicator is when something is valid. Response reliability is the precision of the data collection.

---
examples:

When we talk about measuring intelligence, things can get iffy. Intelligence may be an ill-defined or controversial topic, upon which we use some measurement of some component of intelligence - say, the Raven's Progressive Matrices - the results of which could be influenced by any number of factors.

Measuring stress is another complicated issue. We can use cortisol as an indicator of stress, which may be a better approximation than I.Q. on intelligence, cortisol levels can be influenced by any number of things as well.


---

The 4 steps of the response process are as follows:

Comprehension -> Retrieval -> Estimation -> Answer

It's important when collecting data, that we understand people's responses can mean different things. Their comprehension will vary. Then there's plenty of noise or inaccuracy in how they retrieve information in their craniums. People will also interpret and scale items differently from each other. The enumerator receives answers are subject to the respondent's judgment.

After all of these steps, the respondent now has to respond, which may be dishonest or tainted in some way. You can always change how you word your questions to affect potential responses here.


**Perception, Facts, Quasi-facts:**

We want to define our facts as clearly as possible to prevent them from becoming quasi-facts. It's important therefore to recognize the distinctions between permanent facts, fluctuating facts, habitual or episodic behaviors. We need to define our terms so as to be as precise as possible when taking measurements and comparing amongst people. This of course necessitates that we know how much precision we want, and how people may respond to sensitive questions that get that level of precision. We also want to be aware of culture and context when asking questions, since people may interpret questions in different ways.

So then how do we ask subjective questions? Subjective items can only be known by the individuals, and unobservable, unverifiable things. Motivation is one example.

Belief is a person's perception of facts. These are the closest we can to facts, subjectively. These can also be used to measure a person's knowledge. Expectations can be used to predict facts about the future. Tying these in with desires forms aspirations. Attitudes, as opposed to perception of facts, are perceptions of how things should be or could be. Attitudes are normative. [consult slide and review bookmarked question].

**Selecting Indicators:**

Some constructs are difficult to measure. This could be a communication or discomfort thing, a disinformation thing, etc. We an use proxy indicators that capture observable traits without having to ask respondents awkward questions. Proxy indicators should be correlated with the construct. Proxies should dynamically update as indicators - correlation matches as things change.

We must keep in mind that proxies may not be linearly correlated to the construct we're interested in.

An exclusive indicator is one that is correlated with a construct of interest and no others.
We can have one indicator or a number of indicators to capture differences. The middle ground is an index, or component, which takes multiple predetermined sample items and weigh their ratios of consumption.

When compiling indices, we want to use methods such as principle components analysis iss to remove correlation between components so their contribution isn't overcounted in the construct of concern.

The z-score index doesn't assume anything about weights of each indicator. [study this].


---

Family models, household preferences:

The unitary model describes a situation in which decisions are made as and by a unit, such as just the parents, and that the family's utility is modeled as an individual's.

A dictatorial model is unitary. However, it doesn't mean the dictator doesn't take others' preferences into account.

Another unitary model is where everyone has the same preferences. This is known as the unanimity model.

Usually in families, a more game theoretic scenario is likely. People reaching a stasis since they'll react to each other's decisions. With sufficiently skilled negotiators, this can be efficient.

So how do we test the unitary model?

Note that a unitary model depends only on goods' prices and the aggregate income, whereas in a non-unitary model, people seek to maximize their individual utilities. People's bargaining power within a household will be represented as weights. Bargaining power is influenced by factors such as income, age, gender, and institutions.

We can test whether or not a household is unitary by observing changes in things that'd normally affect bargaining power, without changing preferences. The latter condition would preclude factors such as education, that can affect preferences.
