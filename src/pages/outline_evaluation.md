---
title: "Evaluation Overview"
date: "2020-06-02"
tags: ["rct_design"]
---


<h3>How's and Why's of RCT's</h3>

In order to change things, we first recognize that a problem exists. We perform a "needs assessment." We harbor a theory of change, which bounds the problem, ideas of how to solve it, and the conditions necessary to effect that change without compromising it.

A program then arises out of the Theory of change or "logical framework (logframe)," which we then implement and monitor. Process evaluation is exactly what it sounds like: monitoring and making sure things are being carried out as intended.

We conduct randomized control trials (RCT's) to determine the true treatment effect of programs and policies. They therefore fall into the category of "impact evaluation."

However, due to how *the world works*, real life challenges arise. Even when randomizing, there could be spillover, contamination, and political challenges.


For testing multiple hypotheses within one experiment, we need sufficient sample size. The treatment arms need to represent a meaningful amount of people. In the case of combination experiments, it's good to determine whether or not a combination experiment is more effective than the sum of its parts.

The Learn2Read program's results -- that students who participated jumped on average a full reading level (many baseline non-readers jumped from 0 to 1, and baseline readers jumped from 0 to 1 and 1 to [spread across 2, 3, 4]). A pre-post maesurement would overestimate, whereas a simple difference between participants and non-participants would be biased. Instead, difference-in-difference is used to best estimate the true effect of the L2R program.

cont.

---

In 2003, Kenya eliminated school fees. This increased school enrollment by 30%, from 5.9 million to 7.6 million (2002 - 2005). The surge in student attendance lead to logistical challenges. There was a shortage of teachers (it's estimated they'd need an additional 60k to their 175k), and teacher absenteeism is as high as 20% in parts of Kenya. Students don't show up as a result. Then there's the difference in ability levels of students, paltry learning resources, and less than 45% of students completing grade 1.

In 2005, International Child Support Africa (ICS) introduced 120 contract teachers to Western Kenya's primary schools in order to help with the teacher shortage. However, these contract teachers -- while locally hired and therefore held accountable -- had less training and were paid less than the Ministry of Education teachers they were supplementing.

These contract teachers worked on an annual contract basis. Perhaps they'd be more motivated to do well, lest their contract be terminated! This is vaguely reminisent of the Balsakhi intervention of 2002-2003 in India. In any case, normal teachers have expressed concerns that contract teachers tarnish the pride and integrity of their profession. That is, they're butthurt.

That sets the stage. The ICS's 2005 program was meant to address the heterogeneity, teacher accountability, and class size problems. 

In the schools that received the contract teachers, the classes were split so as to reduce size. In one case, if the classes were split randomly, there's a chance they'd be taught either by a contract teacher or a government teacher. In the other case, classes were split according to ability. Then both contract teachers and government teachers would teach high and low ability level students.

cont.
